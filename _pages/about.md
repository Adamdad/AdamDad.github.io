---
permalink: /
title: "Xingyi Yang"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>

 🚀👨‍💻🥁💡Hi, my name is Xingyi Yang (Adam)💡🥁👨‍💻🚀. I am a third-year Ph.D student at [National University of Singapore(NUS)](https://www.nus.edu.sg/), affiliated with the [Learning and Vision Lab](http://www.lv-nus.org). I am working under the supervision of [Prof.Xinchao Wang](https://www.eng.nus.edu.sg/ece/staff/wang-xinchao/). 

My current research interest lies in **Deep Model Reuse** and its Applications:
- **Deep Model Reuse**: Here, I teach AI systems to mimic students, learning new skills from older models and human experience, to become Jacks of all trades. Or, towards Artificial General Intelligence (AGI).
- **Compositionality & Modularity**: This is like playing a game of LEGO, where I piece together elements from various tasks, concepts, and logic, crafting cost-effective AI masterpieces.
- **ML and Applications**: Call me a machine learning fanatic (my brain's practically an algorithm by now), I particularly interested in its applications within computer vision and multimodal areas – all, hopefully, with a side of solid theory. 

<!-- My work centers on generative models (especially diffusion-based), representation learning, trustworthy learning (emphasizing interpretability and robustness), and graph learning. -->
<!-- - Efficiency, that empowers the AI learn with minimum computation and data requirement.  -->
<!-- - Data Efficency. Focus on self-supervised & semi-supervised & weak-supervised learning or learning with synthesized data. -->

[CV](http://adamdad.github.io/files/Resume_Xingyi_Yang_202305715.pdf)

I believe in [Slow Science](http://slow-science.org/)

